{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 00:03:55.622461: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 00:03:56.262216: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-15 00:03:56.262270: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-15 00:03:56.262276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import ecoset\n",
    "import categorization as cat\n",
    "import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "100 images from Ecoset + CUB200.\n",
    "* Superordinate: 50 vehicles and 50 animals\n",
    "* Basic: 25 cars, 25 busses, 25 dogs, 25 birds\n",
    "* Subordinate: 5 species of birds\n",
    "\n",
    "Images preprocessed by centering the features and resizing to 224x224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/deepCats/animal/bird/CUB_005.Crested_...</td>\n",
       "      <td>Crested_Auklet_0021_794938.jpg</td>\n",
       "      <td>animal</td>\n",
       "      <td>bird</td>\n",
       "      <td>CUB_005.Crested_Auklet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./images/deepCats/animal/bird/CUB_005.Crested_...</td>\n",
       "      <td>Crested_Auklet_0028_794951.jpg</td>\n",
       "      <td>animal</td>\n",
       "      <td>bird</td>\n",
       "      <td>CUB_005.Crested_Auklet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./images/deepCats/animal/bird/CUB_005.Crested_...</td>\n",
       "      <td>Crested_Auklet_0036_794905.jpg</td>\n",
       "      <td>animal</td>\n",
       "      <td>bird</td>\n",
       "      <td>CUB_005.Crested_Auklet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./images/deepCats/animal/bird/CUB_005.Crested_...</td>\n",
       "      <td>Crested_Auklet_0011_794927.jpg</td>\n",
       "      <td>animal</td>\n",
       "      <td>bird</td>\n",
       "      <td>CUB_005.Crested_Auklet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./images/deepCats/animal/bird/CUB_005.Crested_...</td>\n",
       "      <td>Crested_Auklet_0006_1813.jpg</td>\n",
       "      <td>animal</td>\n",
       "      <td>bird</td>\n",
       "      <td>CUB_005.Crested_Auklet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  ./images/deepCats/animal/bird/CUB_005.Crested_...   \n",
       "1  ./images/deepCats/animal/bird/CUB_005.Crested_...   \n",
       "2  ./images/deepCats/animal/bird/CUB_005.Crested_...   \n",
       "3  ./images/deepCats/animal/bird/CUB_005.Crested_...   \n",
       "4  ./images/deepCats/animal/bird/CUB_005.Crested_...   \n",
       "\n",
       "                             name    cat1  cat2                    cat3  \n",
       "0  Crested_Auklet_0021_794938.jpg  animal  bird  CUB_005.Crested_Auklet  \n",
       "1  Crested_Auklet_0028_794951.jpg  animal  bird  CUB_005.Crested_Auklet  \n",
       "2  Crested_Auklet_0036_794905.jpg  animal  bird  CUB_005.Crested_Auklet  \n",
       "3  Crested_Auklet_0011_794927.jpg  animal  bird  CUB_005.Crested_Auklet  \n",
       "4    Crested_Auklet_0006_1813.jpg  animal  bird  CUB_005.Crested_Auklet  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv\n",
    "df = pd.read_csv(\"./deepCatsImages.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from file...\n",
      "(100, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "imgFile = \"./images/deepCatsImages.npy\"\n",
    "\n",
    "if not os.path.exists(imgFile):\n",
    "    # Preallocate array for images\n",
    "    images = np.zeros((df.shape[0], 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "    # Loop through images\n",
    "    for i, row in df.iterrows():\n",
    "        # Load image\n",
    "        img = Image.open(row[\"path\"])\n",
    "\n",
    "        # Preprocess image\n",
    "        img = ecoset.preprocess_alexnet(img)\n",
    "\n",
    "        # Add image to array\n",
    "        images[i] = img\n",
    "\n",
    "    # Save images as a npy\n",
    "    np.save(imgFile, images)\n",
    "else:\n",
    "    # Load images from npy\n",
    "    print(\"Loading images from file...\")\n",
    "    images = np.load(imgFile)\n",
    "\n",
    "print(images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and representations\n",
    "Generate representations from AlexNet trained in Mehrer et al 2022. \n",
    "* 10 models are trained on Ecoset (basic-level categories)\n",
    "* 10 models are trained on ImageNet (mixed levels of abstraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 00:03:58.010722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.018652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.019071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.020373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 00:03:58.020597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.020906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.021194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.440313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.440626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.440904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 00:03:58.441155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3285 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights from ./models/AlexNet/ecoset_training_seeds_01_to_10/training_seed_01/model.ckpt_epoch89 loaded successfully.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 54, 54, 64)        23296     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 26, 26, 64)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 26, 26, 192)       307392    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 12, 12, 192)       0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 12, 12, 384)       663936    \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 12, 12, 384)       1327488   \n",
      "                                                                 \n",
      " conv5 (Conv2D)              (None, 12, 12, 256)       884992    \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " fc6 (Conv2D)                (None, 5, 5, 4096)        26218496  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 4096)        0         \n",
      "                                                                 \n",
      " fc7 (Conv2D)                (None, 5, 5, 4096)        16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 4096)        0         \n",
      "                                                                 \n",
      " fc8 (Conv2D)                (None, 5, 5, 565)         2314805   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 565)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 565)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,521,717\n",
      "Trainable params: 48,521,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load example model\n",
    "weightPath = f\"./models/AlexNet/ecoset_training_seeds_01_to_10/training_seed_01/model.ckpt_epoch89\"\n",
    "model = ecoset.make_alex_net_v2(weights_path=weightPath)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading representations from file for seed 01...\n",
      "Loading representations from file for seed 02...\n",
      "Loading representations from file for seed 03...\n",
      "Loading representations from file for seed 04...\n",
      "Loading representations from file for seed 05...\n",
      "Loading representations from file for seed 06...\n",
      "Loading representations from file for seed 07...\n",
      "Loading representations from file for seed 08...\n",
      "Loading representations from file for seed 09...\n",
      "Loading representations from file for seed 10...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 100, 102400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# Get ecoset representations\n",
    "ecosetReps = np.zeros((len(seeds), images.shape[0], 4096 * 5 * 5), dtype=np.float32)\n",
    "for i, seed in enumerate(seeds):\n",
    "    repFile = f\"./representations/ecoset/seed{seed:02}_reps.npy\"\n",
    "    \n",
    "    if not os.path.exists(repFile):\n",
    "        # Load model\n",
    "        weightPath = f\"./models/AlexNet/ecoset_training_seeds_01_to_10/training_seed_{seed:02}/model.ckpt_epoch89\"\n",
    "        model = ecoset.make_alex_net_v2(weights_path=weightPath)\n",
    "\n",
    "        # Get activation from penultimate layer\n",
    "        layer = model.get_layer(\"fc7\")\n",
    "        model = tf.keras.Model(model.input, layer.output)\n",
    "\n",
    "        # Get representations\n",
    "        reps = model.predict(images)\n",
    "        # Flatten representation\n",
    "        reps = reps.reshape(reps.shape[0], -1)\n",
    "\n",
    "        # Save representations\n",
    "        np.save(repFile, reps)\n",
    "    else:\n",
    "        print(f\"Loading representations from file for seed {seed:02}...\")\n",
    "        reps = np.load(repFile)\n",
    "\n",
    "    # Add rep to big representation array\n",
    "    ecosetReps[i] = reps\n",
    "\n",
    "ecosetReps.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading representations from file for seed 01...\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_02/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_03/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_04/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_05/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_06/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_07/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_08/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 50ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_09/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Weights from ./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_10/model.ckpt_epoch89 loaded successfully.\n",
      "4/4 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 00:56:46.391997: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-05-15 00:56:46.447784: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-05-15 00:56:46.502862: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-05-15 00:56:46.562265: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 100, 102400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get imagenet representations\n",
    "imagenetReps = np.zeros((len(seeds), images.shape[0], 4096 * 5 * 5), dtype=np.float32)\n",
    "for i, seed in enumerate(seeds):\n",
    "    repFile = f\"./representations/imagenet/seed{seed:02}_reps.npy\"\n",
    "    \n",
    "    if not os.path.exists(repFile):\n",
    "        # Load model\n",
    "        weightPath = f\"./models/AlexNet/ILSVRC_training_seeds_01_to_10/training_seed_{seed:02}/model.ckpt_epoch89\"\n",
    "        model = ecoset.make_alex_net_v2(weights_path=weightPath,\n",
    "                                        output_shape=1000)\n",
    "\n",
    "        # Get activation from penultimate layer\n",
    "        layer = model.get_layer(\"fc7\")\n",
    "        model = tf.keras.Model(model.input, layer.output)\n",
    "\n",
    "        # Get representations\n",
    "        reps = model.predict(images)\n",
    "        # Flatten representation\n",
    "        reps = reps.reshape(reps.shape[0], -1)\n",
    "\n",
    "        # Save representations\n",
    "        np.save(repFile, reps)\n",
    "    else:\n",
    "        print(f\"Loading representations from file for seed {seed:02}...\")\n",
    "        reps = np.load(repFile)\n",
    "\n",
    "    # Add rep to big representation array\n",
    "    imagenetReps[i] = reps\n",
    "\n",
    "imagenetReps.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
